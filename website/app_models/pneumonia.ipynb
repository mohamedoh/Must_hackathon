{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"markdown","metadata":{},"source":["# Importing the necessary libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report,confusion_matrix\n","from keras.callbacks import ReduceLROnPlateau\n","import cv2\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["labels = ['PNEUMONIA', 'NORMAL']\n","img_size = 150\n","def get_training_data(data_dir):\n","    data = [] \n","    for label in labels: \n","        path = os.path.join(data_dir, label)\n","        class_num = labels.index(label)\n","        for img in os.listdir(path):\n","            try:\n","                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n","                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n","                data.append([resized_arr, class_num])\n","            except Exception as e:\n","                print(e)\n","    return np.array(data)"]},{"cell_type":"markdown","metadata":{},"source":["# Loading the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["train = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/train')\n","test = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/test')\n","val = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/val')"]},{"cell_type":"markdown","metadata":{},"source":["# Data Visualization & Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["l = []\n","for i in train:\n","    if(i[1] == 0):\n","        l.append(\"Pneumonia\")\n","    else:\n","        l.append(\"Normal\")\n","sns.set_style('darkgrid')\n","sns.countplot(l)        "]},{"cell_type":"markdown","metadata":{},"source":["**The data seems imbalanced . To increase the no. of training examples, we will use data augmentation**"]},{"cell_type":"markdown","metadata":{},"source":["**Previewing the images of both the classes**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize = (5,5))\n","plt.imshow(train[0][0], cmap='gray')\n","plt.title(labels[train[0][1]])\n","\n","plt.figure(figsize = (5,5))\n","plt.imshow(train[-1][0], cmap='gray')\n","plt.title(labels[train[-1][1]])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x_train = []\n","y_train = []\n","\n","x_val = []\n","y_val = []\n","\n","x_test = []\n","y_test = []\n","\n","for feature, label in train:\n","    x_train.append(feature)\n","    y_train.append(label)\n","\n","for feature, label in test:\n","    x_test.append(feature)\n","    y_test.append(label)\n","    \n","for feature, label in val:\n","    x_val.append(feature)\n","    y_val.append(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Normalize the data\n","x_train = np.array(x_train) / 255\n","x_val = np.array(x_val) / 255\n","x_test = np.array(x_test) / 255"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# resize data for deep learning \n","x_train = x_train.reshape(-1, img_size, img_size, 1)\n","y_train = np.array(y_train)\n","\n","x_val = x_val.reshape(-1, img_size, img_size, 1)\n","y_val = np.array(y_val)\n","\n","x_test = x_test.reshape(-1, img_size, img_size, 1)\n","y_test = np.array(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# With data augmentation to prevent overfitting and handling the imbalance in dataset\n","\n","datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.2, # Randomly zoom image \n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip = True,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","\n","datagen.fit(x_train)"]},{"cell_type":"markdown","metadata":{},"source":["# Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = Sequential()\n","model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n","model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n","model.add(Dropout(0.1))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n","model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n","model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n","model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n","model.add(Flatten())\n","model.add(Dense(units = 128 , activation = 'relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(units = 1 , activation = 'sigmoid'))\n","model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(datagen.flow(x_train,y_train, batch_size = 32) ,epochs = 12 , validation_data = datagen.flow(x_val, y_val) ,callbacks = [learning_rate_reduction])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n","print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"]},{"cell_type":"markdown","metadata":{},"source":["# Analysis after Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["epochs = [i for i in range(12)]\n","fig , ax = plt.subplots(1,2)\n","train_acc = history.history['accuracy']\n","train_loss = history.history['loss']\n","val_acc = history.history['val_accuracy']\n","val_loss = history.history['val_loss']\n","fig.set_size_inches(20,10)\n","\n","ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n","ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n","ax[0].set_title('Training & Validation Accuracy')\n","ax[0].legend()\n","ax[0].set_xlabel(\"Epochs\")\n","ax[0].set_ylabel(\"Accuracy\")\n","\n","ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n","ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n","ax[1].set_title('Testing Accuracy & Loss')\n","ax[1].legend()\n","ax[1].set_xlabel(\"Epochs\")\n","ax[1].set_ylabel(\"Training & Validation Loss\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["predictions = model.predict_classes(x_test)\n","predictions = predictions.reshape(1,-1)[0]\n","predictions[:15]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cm = confusion_matrix(y_test,predictions)\n","cm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize = (10,10))\n","sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = labels,yticklabels = labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["correct = np.nonzero(predictions == y_test)[0]\n","incorrect = np.nonzero(predictions != y_test)[0]"]},{"cell_type":"markdown","metadata":{},"source":["**Some of the Correctly Predicted Classes**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["i = 0\n","for c in correct[:6]:\n","    plt.subplot(3,2,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.imshow(x_test[c].reshape(150,150), cmap=\"gray\", interpolation='none')\n","    plt.title(\"Predicted Class {},Actual Class {}\".format(predictions[c], y_test[c]))\n","    plt.tight_layout()\n","    i += 1"]},{"cell_type":"markdown","metadata":{},"source":["**Some of the Incorrectly Predicted Classes**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["i = 0\n","for c in incorrect[:6]:\n","    plt.subplot(3,2,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.imshow(x_test[c].reshape(150,150), cmap=\"gray\", interpolation='none')\n","    plt.title(\"Predicted Class {},Actual Class {}\".format(predictions[c], y_test[c]))\n","    plt.tight_layout()\n","    i += 1"]},{"cell_type":"markdown","metadata":{},"source":["## Saving model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save(\"pneumonia_model.h5\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
